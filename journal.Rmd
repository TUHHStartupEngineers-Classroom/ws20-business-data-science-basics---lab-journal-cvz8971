---
title: "Journal (reproducible report)"
author: "Nele Helena Thomsen"
date: "2020-11-28"
output:
  html_document:
    toc: true
    toc_float: true
    collapsed: false
    number_sections: true
    toc_depth: 3
    #code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(message=FALSE,warning=FALSE, cache=TRUE)
```

Last compiled: `r Sys.Date()`


So far this is just a blog where you can write in plain text and serve your writing to a webpage. One of the main purposes of this lab journal is to record your progress learning R. The reason I am asking you to use this process is because you can both make a website, and a lab journal, and learn R all in R-studio. This makes everything really convenient and in the same place. 

So, let's say you are learning how to make a histogram in R. For example, maybe you want to sample 100 numbers from a normal distribution with mean = 0, and standard deviation = 1, and then you want to plot a histogram. You can do this right here by using an r code block, like this:

When you knit this R Markdown document, you will see that the histogram is printed to the page, along with the R code. This document can be set up to hide the R code in the webpage, just delete the comment (hashtag) from the cold folding option in the yaml header up top. For purposes of letting yourself see the code, and me see the code, best to keep it the way that it is. You'll learn that all of these things and more can be customized in each R code block.



First, it is necessary to load the ... packages ....

```{r}
# packages
pkgs_cran <- c(
  "fs",         # working with the file system
  "readxl",     # reading excel files
  "writexl",    # saving data as excel files
  "tidyverse",  # dplyr, ggplot2, tibble, tidyr, readr, purrr, stringr, forcats
  "lubridate",  # working with dates and times
  "devtools",   # used to install non-CRAN packages
  "RSQLite",    # to open up a connection to the database
  "dplyr",
  "DBI",
  "httr",       # for http requests
  "glue",       # concatenation and interpolation of strings
  "jsonlite",   # JSON structure <-> character format
  "rstudioapi", # credentials
  "rvest",      # finding the relevant fields which contain the desired information
  "stringr",    # for data cleaning and preparation 
  "stringi",    # character string/ text processing
  "xopen",      # quickly opening URLs
#  "purrr",      # suite of functions for iteration and functional programming
  "furrr",      # parallel Processing
  "data.table", # alternative to default data.frame or tibble to handle tabular data
  "vroom",      # fast reading in of delimited files
  "tictoc",     # counter
  "ggmap",     # for map_data 
  "mapsapi",   # for google maps API
  "leaflet"     # visualizing the route from google maps
)
install.packages(pkgs_cran)  

install.packages()
install.packages()


# libraries
library("writexl")
library("fs")
library("devtools")
library(tidyverse)
library(readxl)
library(lubridate)
library("RSQLite")
library("dplyr")
library("DBI")
library(httr)
library(glue)
library(jsonlite)
library("rstudioapi")
library(rvest)
library("stringr")
library(xopen)
library(stringi)
library(furrr)
library(data.table)
library(vroom)
library(tictoc)
library(maps)
library(ggmap)
library(mapsapi)
library(leaflet)

```

# Intro to the tidyverse

Text ...

```{r}
# import files
bikes_tbl      <- read_excel("DS_101/00_data/01_bike_sales/01_raw_data/bikes.xlsx")
orderlines_tbl <- read_excel("DS_101/00_data/01_bike_sales/01_raw_data/orderlines.xlsx")
bikeshops_tbl  <- read_excel("DS_101/00_data/01_bike_sales/01_raw_data/bikeshops.xlsx")

# examine data
glimpse(bikeshops_tbl)

# join data
bike_orderlines_joined_tbl <- orderlines_tbl %>%
  left_join(bikes_tbl, by = c("product.id" = "bike.id")) %>%
  left_join(bikeshops_tbl, by = c("customer.id" = "bikeshop.id"))

# wrangling data
bike_orderlines_joined_tbl %>% 
  select(location) %>%
  filter(str_detect(location, "^Hamburg")) %>% 
  unique()

bikeshop_orderlines_wrangled_tbl <- bike_orderlines_joined_tbl %>%
  separate(col    = location,
           into   = c("city", "state"),
           sep    = ", ") %>%
  
  # Add the total price (price * quantity) 
  # Add a column to a tibble that uses a formula-style calculation of other columns
  mutate(total.price = price * quantity) %>%
  
  # Optional: Reorganize. Using select to grab or remove unnecessary columns
  # by exact column name
  select(-...1, -gender) %>%
  
  # by a pattern
  # You can use the select_helpers to define patterns. 
  # Type ?ends_with and click on Select helpers in the documentation
  select(-ends_with(".id")) %>%
  
  # Actually we need the column "order.id". Let's bind it back to the data
  bind_cols(bike_orderlines_joined_tbl %>% select(order.id)) %>% 
  
  # You can reorder the data by selecting the columns in your desired order.
  # You can use select_helpers like contains() or everything()
  select(order.id, contains("order"), contains("model"), contains("category"),
         price, quantity, total.price,
         everything()) %>%
  
  # Rename columns because we actually wanted underscores instead of the dots
  # (one at the time vs. multiple at once)
  rename(bikeshop = name) %>%
  set_names(names(.) %>% str_replace_all("\\.", "_"))

#glimpse(bike_orderlines_joined_tbl)
#glimpse(bikeshop_orderlines_wrangled_tbl)

```

## Sales by location
```{r}
# Manipulate
sales_by_location_tbl <- bikeshop_orderlines_wrangled_tbl %>%
  select(state, total_price) %>%
  mutate(state) %>%                         # add state column
  group_by(state) %>%                       # group by state and summarize sales
  summarize(sales = sum(total_price)) %>%
  mutate(sales_text = scales::dollar(sales, big.mark = ".", 
                                     decimal.mark = ",", 
                                     prefix = "", 
                                     suffix = " €"))
# sales_by_location_tbl

# Visualize
sales_by_location_tbl %>%
  # setup canvas with the columns state (x-axis) and sales (y-axis)
  ggplot(aes(x = state, y = sales)) +
  # geometries
  geom_col(fill = "#2DC6D6") +              # bar plot
  geom_label(aes(label = sales_text)) +     # labels to the bars
  geom_smooth(method = "lm", se = FALSE) +  # trendline
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  # formatting
  scale_y_continuous(labels = scales::dollar_format(big.mark = ".",
                                                    decimal.mark = ",",
                                                    prefix = "",
                                                    suffix = " €")) +
  labs(
    title    = "Revenue by state",
    subtitle = "Most bikes has been sold in North Rhine-Westphalia",
    x = "",
    y = "Revenue"
  )
```

## Sales by location and year
```{r, fig.width=10, fig.height=7}

sales_by_year_state_tbl <- bikeshop_orderlines_wrangled_tbl %>%
  select(order_date, total_price, state) %>%  
  mutate(year = year(order_date)) %>%
  group_by(year, state) %>%
  summarise(sales = sum(total_price)) %>%
  ungroup() %>%
  
  # Format $ Text
  mutate(sales_text = scales::dollar(sales, big.mark = ".",
                                     decimal.mark = ",",
                                     prefix = "",
                                     suffix = " €"))

# sales_by_year_state_tbl 

# Visualize
sales_by_year_state_tbl %>%
  ggplot(aes(x = year, y = sales, fill = state)) +
  # Geometries
  geom_col() +
  facet_wrap(~ state) +
  # Formatting
  scale_y_continuous(labels = scales::dollar_format(big.mark = ".",
                                                    decimal.mark = ",",
                                                    prefix = "",
                                                    suffix = " €")) +
  labs(
    title = "Revenue by year and state",
    subtitle = "Most of the states have an upward trend",
    fill = "State"
  )

# store files
# Excel
bikeshop_orderlines_wrangled_tbl %>%
  write_xlsx("DS_101/00_data/01_bike_sales/02_wrangled_data/bikeshop_orderlines.xlsx")

# CSV
bikeshop_orderlines_wrangled_tbl %>% 
  write_csv("DS_101/00_data/01_bike_sales/02_wrangled_data/bikeshop_orderlines.csv")

# RDS
bikeshop_orderlines_wrangled_tbl %>% 
  write_rds("DS_101/00_data/01_bike_sales/02_wrangled_data/bikeshop_orderlines.rds")

```


# Data Acquisition

Last compiled: `r Sys.Date()`
#```{r}
##install.packages(RSQLite)
#install.packages(dplyr)
#library(RSQLite)
#library(dplyr)
#con <- RSQLite::dbConnect(drv    = SQLite(), 
#                          dbname = #"DS_101/00_data/02_chinook/Chinook_Sqlite.sqlite")
#dbListTables(con)
#tbl(con, "Album")
#```

get directions from the Google Maps Directions API

```{r}

# API parameter
#key <- .......
url <- "https://maps.googleapis.com/maps/api/directions/json?"
modes <- c("driving","transit", "walking", "bicycling")
tra_model <- c("best_guess", "pessimistic", "optimistic")
avoid = c(NA, "tolls", "highways", "ferries", "indoor")
dep_time = Sys.time() + as.difftime(1, units = "hours")


#route = mp_directions(
#  origin = "Schoene Aussicht Hamburg",
#  destination = "Elbphilharmonie Hamburg",
#  #departure_time = dep_time,
#  mode = modes[[1]],  
#  #traffic_model = tra_model[[1]],
#  alternatives = FALSE,
#  key = key,
#  quiet = TRUE
#)
#route_data = mp_get_routes(route)

# visualization
#pal = colorFactor(palette = "Dark2", domain = route_data$alternative_id)
#leaflet() %>% 
#  addProviderTiles("CartoDB.DarkMatter") %>%
#  addPolylines(data = route_data, opacity = 0.9, weight = 6, color = ~pal(alternative_id))


# extract Separate segments
#route_seg = mp_get_segments(route)
#head(route_seg)

#pal = colorFactor(
#  palette = sample(colors(), length(unique(route_seg$segment_id))), 
#  domain = route_seg$segment_id
#)

#leaflet(route_seg) %>% 
#  addProviderTiles("CartoDB.DarkMatter") %>%
#  addPolylines(opacity = 0.9, weight = 6, color = ~pal(segment_id), popup = ~instructions)
```



# Data Wrangling

```{r}
## patent
col_types_patent <- list(
 id = col_character(),
 type = col_skip(), #col_character(),
 number = col_character(),
 country = col_character(),
 date = col_date("%Y-%m-%d"),
 abstract = col_skip(), #col_character(),
 title = col_skip(), #col_character(),
 kind = col_skip(), #col_character(),
 num_claims = col_double(),
 filename = col_skip(), #col_character(),
 withdrawn = col_double()
)
 
patent_tbl <- vroom(
 file       = "patent.tsv/patent.tsv", 
 delim      = "\t", 
 col_types  = col_types_patent,
 na         = c("", "NA", "NULL")
)
#patent_tbl %>% glimpse()
 
## assignee
col_types_assignee <- list(
 id = col_character(),
 type = col_character(),
 name_first = col_skip(), #col_character(),
 name_last = col_skip(), #col_character(),
 organization = col_character()
)
 
assignee_tbl <- vroom(
 file       = "patent.tsv/assignee.tsv", 
 delim      = "\t", 
 col_types  = col_types_assignee,
 na         = c("", "NA", "NULL")
)
#assignee_tbl %>% glimpse()
 
## patent_assignee
col_types_patent_assignee <- list(
 patent_id = col_character(),
 assignee_id = col_character(),
 location_id = col_character()
)

patent_assignee_tbl <- vroom(
 file       = "patent.tsv/patent_assignee.tsv", 
 delim      = "\t", 
 col_types  = col_types_patent_assignee,
 na         = c("", "NA", "NULL")
)
#patent_assignee_tbl %>% glimpse()
 
## uspc
col_types_uspc <- list(
 uuid = col_skip(), #col_character(),
 patent_id = col_character(),
 mainclass_id = col_character(),
 subclass_id = col_skip(), #col_character(),
 sequence = col_character()
)
 
uspc_tbl <- vroom(
 file       = "patent.tsv/uspc.tsv", 
 delim      = "\t", 
 col_types  = col_types_uspc,
 na         = c("", "NA", "NULL")
)

#plan("multiprocess") ########################################
setDT(patent_tbl)
setDT(assignee_tbl)
setDT(patent_assignee_tbl)
setDT(uspc_tbl)
#patent_tbl %>% glimpse()
#patent_assignee_tbl %>% glimpse()
#assignee_tbl %>% glimpse()
#uspc_tbl %>% glimpse()

```

## Patent dominance
The 10 US companies with the most assigned/granted patents.

```{r}
a_p_a_combined <- merge(x = assignee_tbl, y = patent_assignee_tbl, 
                      by.x  = "id", 
                      by.y  = "assignee_id",
                      all.x = TRUE, 
                      all.y = FALSE)
 
a_p_a_combined %>% glimpse()

 
setkey(a_p_a_combined, "id")
#key(a_p_a_combined)
setorderv(a_p_a_combined, c("id", "organization"))
 
a_p_a_combined %>% dim()
#a_p_a_combined$id %>% unique()
a_p_a_combined %>% glimpse()
 
us_patents <- a_p_a_combined %>%
 select(1:3) %>%
 filter(type == "2")
   
us_patents %>% glimpse()
 
us_patents %>%
 group_by(organization) %>%
 summarise(
   count = n()
 ) %>%
 ungroup() %>%
 arrange(desc(count)) %>%
 slice(1:10)
```
## Recent patent activity
top 10 US companies with the most new granted patents for 2019
 
```{r}
a_p_a_p_combined <- merge(x = patent_tbl, y = a_p_a_combined, 
                       by.x    = "id",
                       by.y = "patent_id",
                       all.x = TRUE, 
                       all.y = FALSE)
 
a_p_a_p_combined %>% glimpse()
setkey(a_p_a_p_combined, "id")
#key(a_p_a_p_combined)
#a_p_a_p_combined$withdrawn %>% unique()
setorderv(a_p_a_p_combined, c("id", "organization"))
 
us_patents2019 <- a_p_a_p_combined %>%
  filter(type == "2") %>%
  filter(country == "US") %>%
  filter(date >= "2019-01-01" & date <="2019-12-01") %>%
  filter(withdrawn != 1)  ####################################### richtig ?

#us_patents2019 %>% glimpse()
 
us_patents2019 %>%
  #filter(organization != na) %>%
  group_by(organization) %>%   
  summarise(
     count = n()                       ####################### #* num_claims ?
  ) %>%
  ungroup() %>%
  arrange(desc(count)) %>%
  slice(1:10)

```

## Innovation in Tech
What is the most innovative tech sector? 
For the top 10 companies (worldwide) with the most patents, what are the top 5 USPTO tech main classes?

```{r}
patents_worldwide <- a_p_a_combined %>%
  select(1:4) %>%
  filter(type == "2" | type == "3") %>%
  group_by(organization) %>%
  summarise(
    count = n()
  ) %>%
  ungroup() %>%
  arrange(desc(count)) %>%
  slice(1:10)

patents_worldwide %>% glimpse()
patents_worldwide$organization

uspc_patents <- merge(x = uspc_tbl, y = a_p_a_combined, 
                          by = "patent_id",
                          all.x = TRUE, 
                          all.y = FALSE)


setkey(uspc_patents, "patent_id")
#key(a_p_a_combined)
setorderv(uspc_patents, c("patent_id", "organization"))


tech_patents <- uspc_patents %>%
  filter(sequence == "0") %>%               # filter the data where the uspc class appears in the patent file in first place
  filter(type == "2" | type == "3") %>%     # filter the companies
  select(1,2,6) %>%
  
#uspc_patents <- uspc_patents %>%
  group_by(organization) %>%
  mutate(count = n()) %>%
  ungroup() %>%
  arrange(desc(count)) #%>%
 # slice(1:10)

max <- distinct(tech_patents, count) %>%
  sum(1:10)

tech_patents %>% 
  slice(1:max) %>%
  group_by(mainclass_id) %>%
  summarise(
    count = n()
  ) %>%
  ungroup() %>%
  arrange(desc(count)) %>%
  slice(1:5)
```
257	Active solid-state devices (e.g., transistors, solid-state diodes)
438	Semiconductor device manufacturing: process
370	Multiplex communications
455	Telecommunications
365	Static information storage and retrieval
# Data Visualization

## Time course of the cumulative Covid-19 cases

```{r}
covid_data_tbl <- read_csv("https://opendata.ecdc.europa.eu/covid19/casedistribution/csv")

covid_data_tbl %>% glimpse()

covid_data2020_tbl <- covid_data_tbl %>%
  select(1:5, 7, 11, 12) %>%
  filter(year == 2020)

#covid_data2020_tbl %>% glimpse()

covid_data2020_tbl %>%
  #group_by(continentExp) %>%
  #summarize(continentCases = sum(cases)) %>%
  #ungroup() %>%
  filter(countriesAndTerritories %in% c("Germany", "France","United_Kingdom","Spain", "United_States_of_America")) %>%

  ggplot(aes(month, `Cumulative_number_for_14_days_of_COVID-19_cases_per_100000`)) + 
  geom_line(aes(color = countriesAndTerritories), size = 1) + 
  scale_x_continuous(breaks = 1:11, labels =c('January', 'February','March', 'April','May', 'June','July', 'August','September', 'October','November')) +
  scale_y_continuous(labels = scales::dollar_format(scale = 1e-2, 
                                             prefix = "",
                                             suffix = "M")) +
  labs(
    title = "COVID-19 confirmed cases worldwide",
    subtitle = "As of 11/02/2020, Europe had more cases than the USA",
    x = "Year 2020",
    y = "Cumulative Cases",
    color = "Continent / Country"
  ) + 
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    legend.position = "bottom",
   # legend.direction = "vertical",
    plot.title = element_text(face = "bold"),
  ) +
  coord_cartesian(ylim = c(0, 1000))
  
```


## Distribution of the mortality rate
```{r}
covid_dataworld_tbl <- covid_data_tbl %>%
  select(1:4, 6:10) %>%
  mutate(across(countriesAndTerritories, str_replace_all, "_", " ")) %>%
  mutate(countriesAndTerritories = case_when(
    countriesAndTerritories == "United Kingdom" ~ "UK",
    countriesAndTerritories == "United States of America" ~ "USA",
    countriesAndTerritories == "Czechia" ~ "Czech Republic",
    TRUE ~ countriesAndTerritories
  )) %>%
  group_by(countriesAndTerritories) %>%
  summarize(countryDeaths = sum(deaths)) %>%
  ungroup()

covid_deaths_tbl <- covid_dataworld_tbl %>%
  left_join(covid_data_tbl) %>%
  select(1,2,11) %>%
  group_by(countriesAndTerritories) %>%
  distinct() %>%
  mutate(Mortality_Rate = countryDeaths / popData2019) %>%
  select(1,4) 

covid_deaths_tbl %>% glimpse()
covid_dataworld_tbl %>% glimpse()
world <- map_data("world")
world %>% glimpse()

covid_deaths_tbl %>%
  ggplot() +
  geom_map(data = covid_deaths_tbl,
           map = world,
           aes(map_id = countriesAndTerritories, fill= Mortality_Rate),
           size=0.15,
           colour="darkred" ) +
  scale_y_continuous(labels = scales::percent) +
  #scale_color_continuous(low    = "#95E1EA", high = "#1097A3") +
  expand_limits(x = world$long, y = world$lat)+
  coord_fixed() +
  scale_fill_continuous(low = 'grey', high = 'red') +
  theme(axis.ticks = element_blank(),
        axis.text = element_blank(),
        axis.title = element_blank(),
        legend.position = "right",
        plot.title = element_text(face = "bold")) +
  labs(
    title = "Confirmed COVID-19 deaths relative to the size of the population",
    subtitle = "More than 1.2 Million confirmed COVID-19 deaths worldwide",
    caption = "Date: 12/01/2020",
    color = "Mortality Rate"
  )
```

